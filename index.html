<!DOCTYPE html>
<html lang="en">

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-92YNKNRNLT"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-92YNKNRNLT');
    </script>

    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VideoGameBunny: Towards vision assistants for video games</title>
    <link rel="stylesheet" href="./static/css/prismer.css">
    <link rel="stylesheet" href="./static/css/shikun.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap"
        rel="stylesheet">

    <style>
        .container.blog#first-content {
            background-color: #E2a3a3;
        }

        footer {
            text-align: center;
            padding: 20px;
            background-color: #f0f0f0;
            margin-top: 20px;
        }

        footer a {
            color: #E2a3a3;
        }

        .videogamebunny {
            color: #696969;
            font-family: sans-serif;
            font-variant: small-caps;
            font-weight: normal;
            letter-spacing: 0.5px;
        }

        .abstract {
            text-align: justify;
            margin-bottom: 1em;
            font-size: 0.9em;
            line-height: 1.6;
        }

        h2 {
            color: #4a4a4a;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }

        .abstract {
            text-align: justify;
            margin-bottom: 1em;
            font-size: 0.9em;
            line-height: 1.6;
        }

        .code-link {
            margin-bottom: 2em;
        }

        h2 {
            color: #4a4a4a;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
        }

        .abstract a,
        .code-link a {
            color: #E2a3a3;
            text-decoration: none;
        }

        .abstract a:hover,
        .code-link a:hover {
            text-decoration: underline;
        }


        #annotation-text-container {
            margin-top: 10px;
            padding: 10px;
            background-color: #f0f0f0;
            border: 1px solid #ccc;
            border-radius: 5px;
            opacity: 0;
            transform: translateY(-20px);
            transition: opacity 0.3s ease, transform 0.3s ease;
        }

        #annotation-text-container.show {
            opacity: 1;
            transform: translateY(0);
        }

        .image-container {
            position: relative;
            display: inline-block;
            max-width: 100%;
            margin-bottom: 1rem;
        }

        .annotation-point {
            position: absolute;
            width: 20px;
            height: 20px;
            background-color: rgba(255, 255, 255, 0.7);
            border: 2px solid #007bff;
            border-radius: 50%;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }

        .annotation-point:hover {
            background-color: rgba(0, 123, 255, 0.5);
        }

        .annotation-text {
            margin-top: 1rem;
            font-size: inherit;
            font-family: inherit;
            line-height: inherit;
            color: inherit;
            display: none;
        }
    </style>
</head>

<body>
    <div class="container blog" id="first-content">
        <div class="blog-title">
            <div class="blog-intro">
                <div>
                    <h1 class="title"><span class="videogamebunny">VideoGameBunny</span>: Towards vision assistants for
                        video games</h1>
                    <p class="author">Anonymous Author</p>
                    <p class="summary">
                        We introduce <span class="videogamebunny">VideoGameBunny</span>, a LLaVA-style model
                        designed specifically
                        for understanding video game images. We present a comprehensive dataset of game images and
                        instruction pairs, demonstrating that our model can outperform larger state-of-the-art models in
                        game-related tasks, paving the way for
                        advanced AI assistants in video game understanding, playing, commentary, and debugging.
                    </p>
                    <div>
                        <a href="#" class="button icon" style="background-color: rgba(39, 38, 42, 0.2)">Paper <i
                                class="far fa-book-open"></i></a>
                        <a href="https://huggingface.co/datasets/VideoGameBunny/Dataset" class="button icon"
                            style="background-color: rgba(39, 38, 42, 0.2)">Dataset <i class="far fa-code"></i></a>
                        <a href="https://huggingface.co/VideoGameBunny/VideoGameBunny-V1" class="button icon"
                            style="background-color: rgba(39, 38, 42, 0.2)">Model <i
                                class="fa-light fa-face-smiling-hands"></i></a>
                    </div>
                </div>
                <div class="info">
                    <p>Paper Under Review</p>
                </div>
            </div>

            <div class="blog-cover">
                <img class="foreground" src="./static/images/banner.png" alt="VIDEOGAMEBUNNY banner">
                <img class="background" src="./static/images/banner.png" alt="VIDEOGAMEBUNNY banner background">
            </div>
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1 class="section">
            Abstract
        </h1>
        <p class="abstract">
            Large multimodal models (LMMs) hold substantial promise across various domains, from personal assistance in
            daily
            tasks to sophisticated applications like medical diagnostics. However, their capabilities have limitations
            in the
            video game domain, such as challenges with scene understanding, hallucinations, and inaccurate descriptions
            of video
            game content, especially in open-source models. This paper describes the development of <span
                class="videogamebunny">VideoGameBunny</span>, a LLaVA-style model based on Bunny, specifically tailored
            for
            understanding images from video games. We release intermediate checkpoints, training logs, and an extensive
            dataset
            comprising 185,259 video game images from 413 titles, along with 389,565 image-instruction pairs that
            include image
            captions, question-answer pairs, and a JSON representation of 16 elements of 136,974 images. Our experiments
            show
            that our high quality game-related data has the potential to make a relatively small model outperform the
            much
            larger state-of-the-art model LLaVa-1.6-34b (which has more than 4x the number of parameters). Our study
            paves the
            way for future research in video game understanding on tasks such as playing, commentary, and debugging.
        </p>

    </div>


    <div class="container blog main second" id="blog-main">
        <h1 class="section">
            Sample
        </h1>
        <p>
            Below is a sample annotated image in the image-to-JSON subset of our dataset, containing a detailed summary
            of the
            image, from a high-level description to details about the surroundings, player inventory, and watermark on
            the image.
        </p>

        <p class="note" style="margin-top: 1em; margin-bottom: 1em; font-style: italic;">
            Note: Click on the circles in the image to view detailed annotations.
        </p>


        <div class="image-container">
            <img src="./static/images/ee213477-cb0c-4897-92c4-96c273aceb40.jpeg" alt="VideoGameBunny Cover">
            <div class="annotation-point" style="top: 80%; left: 85%;"
                data-text="The player has 30 rounds in the currently equipped magazine, 42 spare rounds, 1 grenade, and 4 of an unidentified item.">
            </div>
            <div class="annotation-point" style="top: 40%; left: 40%;"
                data-text="A set of double doors, secured by a chain and padlock"></div>
            <div class="annotation-point" style="top: 30%; left: 75%;"
                data-text="A whimsically painted mural on the right wall, depicting a panda bear and a monkey playfully engaged in a soccer match.">
            </div>
            <div class="annotation-point" style="top: 40%; left: 15%;"
                data-text="Two armed soldiers, clad in military fatigues, are positioned strategically within a room.">
            </div>
            <div class="annotation-point" style="top: 3%; left: 90%;" data-text="Watermark: Gamer's Little Playground">
            </div>
            <div class="annotation-point" style="top: 12%; left: 38%;"
                data-text="The room is dimly lit with the primary light source appearing to be a fluorescent light fixture on the ceiling.">
            </div>
        </div>
        <div id="annotation-text-container"></div>


    </div>


    <footer>
        <p>This website is using the template of <a href="https://shikun.io/projects/prismer">Prismer</a> by Shikun
            Liu.</p>
    </footer>


    <script>
        const textContainer = document.getElementById('annotation-text-container');
        document.querySelectorAll('.annotation-point').forEach(point => {
            point.addEventListener('click', function () {
                const text = this.getAttribute('data-text');
                textContainer.textContent = text;
                textContainer.classList.remove('show');
                void textContainer.offsetWidth; // Trigger reflow
                textContainer.classList.add('show');
            });
        });
    </script>

</body>

</html>